# Systems and Networks

| Topic |
| --- |
[Instruction Set Architecture](#instruction-set-architecture) |
[Processor Design](#processor-design) |
[Discontinuities](#discontinuities) |
[Pipelining](#pipelining) |

## Overview

| Abstraction Levels |
| --- |
compiler |
instruction set |
datapath and FSM |
combinational and sequential logic |
logic gates |
transistors |
electrons and holes |

---

## Instruction Set Architecture
The meeting point between software and hardware. 

### Simple Machine Model
```
processor ----- memory
            |
            --- devices
```
We focus on the processor

| Common HLL Feature Set |
| --- |
[Expressions and Assignment Statements](#expressions-and-assignment-statements) |
[High-Level Data Abstractions](#high-level-data-abstractions) |
[Conditional Statements and loops](#conditional-statements-and-loops) |
[Procedure Calls](#procedure-calls) |

### Expressions and Assignment Statements
`c = a + b` maps to `add c, a, b`  
`d = e - f` maps to `sub d, e, f`  
These are *binary* instructions, since they use two operands to produce a result.

Instead of storing these in memory, store operands in registers for calculations.
- faster to access
- better *addressability* (fewer bits needed per instruction)

Because the variables themselves are stored in memory, instructions are needed to move back and forth between memory and processor registers -> these are the `load` and `store` instructions.

To compile `a = b + c`:
```
ld  r2, b
ld  r3, c
add r1, r2, r3
st  r1, a
```

This is done with 4 instructions instead of 1, but things will become more efficient when the variables need to be reused.  

### High-Level Data Abstractions
#### Structs
```
a : struct {
    int b;
    int c;
}
```

In memory:
```
   ___
a |_b_| 100
  |_c_| 104
```

To load `b` and `c` into registers, we use a new addressing mode: `base + offset`
```
ld r2, 0 // b
ld r3, 4 // c
```

#### Operand Granularity
type | bits | size
--- | --- | ---
char | 8 | byte
short | 16 | half word
int | 32 | word
long | 32/64 |

addressability - smallest precision operand that can be individually accessed in memory

#### Operand Alignment
```c
char a;
char b[3];
```
```
 ______ ______ ______ _____
|_b[2]_|_b[1]_|_b[0]_|__a__|
  103    102    101    100
```
- packing operands into a single word to save space
- ISA may support `ld` and `st` with different precision

```c
char a;
int b;
```
In this case, packing doesn't help (space/time tradeoff)
```
 ___ ___ ___ ___
|_b_|_b_|_b_|_a_| 100
|___|___|___|_b_| 104
```
Packing this way means you have to access memory twice to get b.  
The processor will have to pull two words, and then figure out a way to extract the int.

```
 ___ ___ ___ ___
|___|___|___|_a_| 100
|_b_|_b_|_b_|_b_| 104
```
Therefore, here it is okay to waste space.

#### Endianness
Overall, big vs. little is a wash.

##### Little Endian
Least significant byte (LSD) at word address.
```
 ___ ___ ___ ___
|___|___|___|___| 100
|___|___|___|___| 104
 +3  +2  +1  +0
```

##### Big Endian
Most significant byte at word address.
```
     ___ ___ ___ ___
100 |___|___|___|___|
104 |___|___|___|___|
     +0  +1  +2  +3
```

#### Accessing Array Operands
```c
int a[100];
```

Usually arrays are used with for loops to calculate the index.  
New addressing mode -> base + index.

```
     ______
100 |______| a[0]
104 |______| a[1]
108 |______| a[2]
    |   .  |
    |   .  |
    |___.__|
128 |______| a[7]
132 |______| a[8]
```
Using base + offset getting to a[8] requires the compiler to calculate the offset.  
With base + index, this is done in the registers???
```
rb = 100
ld r8, 32  # using base + offset
```

### Conditional Statement
#### If
```c
if <predicate> {
  ...
} else {
  ...
}
```

- introduction of PC (PC-relative addressing mode)
- one new instruction: `beq r1, r2, offset`

#### Switch
```c
switch (k) {
  case 0:
  case 1:
  case 2:
  case 3:
  default:
}
```

- simulate via if/else
- use `k` at runtime to directly branch
- jump table (store addresses for each case)

##### Other needed embellishments
- indirect addressing mode (`j@r1`, `PC <- memory[r1]`)
- MIPS has SLT istruction for bounds checking

#### Loop
```c
for () {
  ...
}
```

Nothing new needed

### Compiling Function Calls
```c
int foo(formal-parameters) {
  <decl local-variables>
  /* code */
  return(<value>)
}

int main() {
  <decl local-variables>
  return-value = foo(actual-params);
  /* continue upon returning */
}
```
1. ensure that caller state is preserved upon return
2. pass parameters to callee
3. remember return address
4. transfer control to callee
5. allocate space for callee's local variables
6. receive return values and give them to caller
7. return to point of call

#### State of the Caller
The compiler ensures that memory used is distinct. Therefore, we only need to save processor registers, and restore them upon return.

To do this, we use a stack (abstraction in memory).

Because not all registers have to be saved, and the callee may not always have to use all registers, the task of saving and restoring registers is given to the callee.

#### JAL - Jump and Link
Remembering return address and jumping to target procedure

`JAL rlink, rtarget`: `rlink <- PC`, `PC <- rtarget`

#### Passing Parameters / Returning Result
Pushing to the stack not always necessary if there are available registers

#### Overall
- use the stack sparingly

#### Software Convention
Register | Use
--- | ---
s0-s2 | caller
t0-t2 | temporary
a0-a2 | parameter passing
v0 | return value
ra | return address (rlink)
at | target address (rtarget)
sp | stack pointer

#### Stack Convention
- decrease and push
- increase and pop

Stack |
| --- |
local variables |
saved a registers |
previous return address |
additional return values |
addition parameters |
saved t registers |

This is the activation record of currently executing procedure.  
On a call chain, there is an activation record for each function call.  
All of it is done by the compiler.

Step | Actor | Action
--- | --- | ---
1 | caller | save registers t0-t3 on stack (if needed on return)
2 | caller | place parameters in a0-a2 (use stack for additional)
3 | caller | allocate space for any additional return values
4 | caller | save previous return address currently in `ra` onto stack
5 | caller | execute `JAL at, ra`
6 | caller | store previous frame pointer, and copy stack pointer into frame pointer
7 | callee | save registers that will be used during execution
8 | callee | allocate space for local variables
9 | callee | restor any saved registers from stack
10 | caller | restore previous return address to `ra`
11 | caller | store additional return values (if needed)
12 | caller | move stack pointer to discard additional parameters
13 | caller | restore any t registers from stack

#### Registers Reserved for the Compiler
- sp -> stack pointer
- fp -> frame pointer
- at -> target register
- ra -> link register

#### Frame Pointer
Retains a known point in the activation record for the function, and will not change during execution.

### ISA for HLL
HLL | ISA
--- | ---
expression and assignment | ALU instruction (ADD, NAND)
data abstraction | addressing modes (register, base + offset)
predicated execution and loops | branch instruction (BEQ)
procedure call | jump and link (JAL)

### Architectural Styles
- stack oriented
- memory oriented
- accumulator oriented
- register oriented
- hybrid

### Instruction Format
Grouped by operand number.

---

## Processor Design
The instruction-set is not a description of the processor implementation; it is the "contract between hardware and software".

### Logic Design Review
In a clock cycle, changes to the registers are made on the rising edge (the logic action).

### Register File
- input -> address -> clock -> r/w (0-1 bits) -> output
- you don't have to look at all the registers at a time, so you have a register file

#### Dual-ported Register File
- allows you to operate on two registers, and write to another at the same time (???)

### RAM (Random Access Memory)
Access memory in any order

### DRAM (Dynamic Random Access Memory)
- holds memory more efficiently, but is slow
- works differently from a register file -> it is not clocked, and has level logic

### Program Counter
Given `ADD Rx, Ry, Rz`  
PC -> mem -> IR -> reg file -> ALU -> reg file  
This takes 2 clock cycles with a dual ported register, one to access the IR, one to write to the register file. 

### Delays
- input:
  - setup (before)
  - hold (after)
- output stable (before it can be safely read)
- propagation (wire)
- ALU-op (combinational)

The clock cycle has to be long enough to accomodate all of these delays.
- propagation delay - combinational
- access time - between read enable and output
- set up time - register input must be stable for some amount of time
- hold time - reg input must continue to be stable for some time after rising edge
- transmission(wire) delay - wire traversal time

To determine clock width, take the longest delay between two cycles.

### Finite State Machine (FSM)
??? oops was not listening

### Instructions
#### R-Type
- sequence of ???

### BEQ
Essentially, branch if equal.

If R<sub>x</sub> = R<sub>y</sub>, then `PC <- PC + 1 + signed address offset`

1. R<sub>x</sub> -> A, next step beq 2
2. R<sub>y</sub> -> B, next step beq 3
3. next step beq 4 (z = 1) or ifetch1-clone (z = 0); this is done by prepending the z-bit
4.
5.
6. fetch microstate

Steps 4 - 6 are for calculating the target address.

### Multi-Way Branch
Prepend the opcode to the address (going off the BEQ implementation)

In one clock cycle:  
`state reg -> ROM -> output -> drive datapath -> do the work -> next state`

---

## Discontinuities

- synchronous - occurs at well-defined points of time (state changing from one microstate to the next)
- asynchronous - occurs unexpectedly to other ongoing activities in the system (email notification)

**interrupts** - The way that devices catch the attention of the processor. Interrupts are only caused by external devices (for clarity).

**exceptions** - Internally generated conditions that are synchronous with processor execution. These are usually unintended by the current program.

**traps** - Internally generated, synchronous. Allows the program to "fall into the operating system," which decides what program the user wants.

Type | Sync/Async | Source | Intentional? | Examples
--- | --- | --- | --- | ---
Exception | sync | internal | yes and no | divide by zero
Trap | sync | internal | yes and no | software interrupts
Interrupt | async | external | yes | I/O device completion

### Interrupt Vector Table
Fixed-size table of handler addresses for each type of anticipated discontinuity.

Processor mechanisms are the same regardless of discontinuity type.

### Architectural Enhancements 
1. processor must wait until instruction execution is complete before checking for an interrupt
2. add a hardware line to check for interrupts
3. add a special macro state `INT` to enter at the end of instruction execution if there is an interrupt pending

### FSM
Add `INT` macrostate in addition to `fetch`, `decode`, and `execute`.
To resume normal execution, the program state and point of resumption are needed.

### Cascaded Interrupts

---

## Pipelining

### Branch Prediction
Guess that the branch will not be taken; if this turns out to be true, life is good.

If the guess is wrong, then squash the previous intructions by replacing them with no-ops.

This method is helpful, because the prediction will most likely in fact be correct more than 50% of the time, in the case of a loop. 

### Branch Target Buffer
Hardware solution - use past branch decisions to predict the future

### Program Discontinuities
Can occur at any time